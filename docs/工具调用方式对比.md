# 工具调用方式对比：V1 vs V2/V3

## 核心区别

### Work V1：直接调用（内部集成）
- 工具函数直接在 LangGraph 节点中调用
- 紧耦合架构
- 仅供内部使用

### Work V2/V3：MCP 服务（标准化接口）
- 工具通过 MCP 协议暴露
- 松耦合架构
- 可供外部系统调用

---

## Work V1 的工具调用方式

### 架构图

```
┌─────────────────────────────────────┐
│         FastAPI 应用                 │
│                                      │
│  ┌────────────────────────────────┐ │
│  │      LangGraph 状态机           │ │
│  │                                 │ │
│  │  ┌──────────────────────────┐  │ │
│  │  │  intent_node()           │  │ │
│  │  │  - 意图识别              │  │ │
│  │  └──────────┬───────────────┘  │ │
│  │             │                   │ │
│  │  ┌──────────▼───────────────┐  │ │
│  │  │  kb_node()               │  │ │
│  │  │  - retrieve_kb(q) ◄──────┼──┼─┐
│  │  └──────────────────────────┘  │ │ │
│  │                                 │ │ │
│  │  ┌──────────────────────────┐  │ │ │
│  │  │  order_node()            │  │ │ │
│  │  │  - getdb(q)      ◄───────┼──┼─┤
│  │  │  - exec_sql()    ◄───────┼──┼─┤
│  │  └──────────────────────────┘  │ │ │
│  │                                 │ │ │
│  │  ┌──────────────────────────┐  │ │ │
│  │  │  handoff_node()          │  │ │ │
│  │  │  - record_unanswered() ◄─┼──┼─┤
│  │  │  - handoff_to_human() ◄──┼──┼─┤
│  │  └──────────────────────────┘  │ │ │
│  └─────────────────────────────────┘ │ │
└──────────────────────────────────────┘ │
                                          │
┌──────────────────────────────────────┐ │
│         tools.py                      │ │
│  - retrieve_kb()      ◄───────────────┘
│  - getdb()            ◄─────────────────┘
│  - exec_sql()         ◄─────────────────┘
│  - record_unanswered()◄─────────────────┘
│  - handoff_to_human() ◄─────────────────┘
└──────────────────────────────────────┘
```

### 代码示例

#### 1. 知识库检索节点

```python
# work_v1/graph.py

from tools import retrieve_kb

def kb_node(state: State) -> Dict[str, Any]:
    """知识库节点：RAG 检索并依据参考资料作答。"""
    q = state.get("query", "")
    
    # 直接调用 tools.py 中的函数
    serialized, docs = retrieve_kb(q)
    
    sources = []
    try:
        sources = [getattr(d, "metadata", {}) for d in docs]
    except Exception:
        sources = []
    
    if not docs:
        return {"kb_answer": "", "sources": sources}
    
    # 使用 LLM 生成回答
    prompt = RAG_PROMPT_TEMPLATE.format(context=serialized, question=q)
    msg = llm.invoke(prompt)
    content = str(getattr(msg, "content", msg)).strip()
    
    return {"kb_answer": content, "sources": sources}
```

#### 2. 订单查询节点

```python
# work_v1/graph.py

from tools import getdb, exec_sql, _format_order_nlg

def order_node(state: State) -> Dict[str, Any]:
    """订单查询节点：执行 SQL 并生成客服话术。"""
    q = state.get("query", "")
    
    # 直接调用 getdb 获取 SQL 和参数
    payload = getdb(q)
    sql_text = payload.get("sql")
    params = payload.get("params")
    
    # 直接调用 exec_sql 执行查询
    result = None
    if sql_text and params:
        try:
            runner = RunnableLambda(lambda _: exec_sql(sql_text, list(params))).with_retry()
            result = runner.invoke(None)
        except Exception:
            result = None
    
    if result is None:
        return {"order_summary": "未查到，请输入"人工客服"进行查询"}
    
    # 直接调用格式化函数
    summary = _format_order_nlg(result)
    return {"order_summary": summary}
```

#### 3. 转人工节点

```python
# work_v1/graph.py

from tools import record_unanswered, handoff_to_human

def no_kb_then_handoff_node(state: State) -> Dict[str, Any]:
    """兜底节点：记录未命中问题，并返回转人工渠道信息。"""
    q = state.get("query", "")
    
    # 直接调用记录函数
    record_unanswered(q)
    
    # 直接调用转人工函数
    payload = {"query": q}
    res = handoff_to_human(payload)
    
    return {"human_handoff": res}
```

### 工具函数定义

```python
# work_v1/tools.py

def retrieve_kb(query: str) -> Tuple[str, List[Any]]:
    """根据查询在向量库中检索相似文档。"""
    vs = config.get_vector_store()
    docs: List[Any] = []
    if vs is not None:
        docs = vs.similarity_search(query, k=2)
    serialized = "\n\n".join(
        (f"Source: {getattr(doc, 'metadata', {})}\nContent: {getattr(doc, 'page_content', '')}")
        for doc in docs
    )
    return serialized, docs

def getdb(order_text: str) -> Dict[str, Any]:
    """生成订单查询所需的 SQL 与参数。"""
    oid = _parse_order_id(order_text) or "#20251114001"
    mock = {
        "order_id": oid,
        "status": "processing",
        "amount": 199.0,
    }
    sql = "SELECT order_id, status, amount, updated_at, start_time FROM orders WHERE order_id = %s LIMIT 1"
    params = [oid.lstrip("#")]
    return {"mock": mock, "sql": sql, "params": params}

def exec_sql(sql: str, params: List[Any]) -> Optional[Dict[str, Any]]:
    """执行订单查询 SQL 并返回结构化结果。"""
    db_path = config.get_orders_db_path()
    if not db_path:
        return None
    try:
        conn = sqlite3.connect(db_path)
        cur = conn.cursor()
        cur.execute(sql.replace("%s", "?"), params)
        row = cur.fetchone()
        cur.close()
        conn.close()
        if row:
            return {
                "order_id": str(row[0]),
                "status": str(row[1]),
                "amount": float(row[2]) if row[2] is not None else None,
                "updated_at": str(row[3]) if row[3] is not None else None,
                "start_time": str(row[4]) if len(row) > 4 and row[4] is not None else None,
            }
        return None
    except Exception:
        return None

def record_unanswered(text: str, user_id: Optional[str] = None) -> Dict[str, Any]:
    """将未命中的用户问题记录到本地 SQLite。"""
    db_path = config.get_support_db_path()
    ts = int(time.time())
    conn = sqlite3.connect(db_path)
    cur = conn.cursor()
    cur.execute(
        "CREATE TABLE IF NOT EXISTS unanswered_questions (id INTEGER PRIMARY KEY AUTOINCREMENT, user_id TEXT, text TEXT, created_at INTEGER)"
    )
    cur.execute(
        "INSERT INTO unanswered_questions(user_id, text, created_at) VALUES(?, ?, ?)",
        [user_id, text, ts],
    )
    conn.commit()
    cur.close()
    conn.close()
    return {"ok": True, "db": db_path}

def handoff_to_human(payload: Dict[str, Any]) -> Dict[str, Any]:
    """封装转人工的渠道与载荷。"""
    url = config.HUMAN_SUPPORT_URL
    return {"channel": url or "default", "payload": payload}
```

### 调用流程

```
用户请求
   ↓
FastAPI /chat 接口
   ↓
LangGraph.invoke(state)
   ↓
intent_node() → 识别意图
   ↓
根据意图路由到不同节点：
   ├─ kb_node()
   │    └─ retrieve_kb(query)  ← 直接调用
   │         └─ config.get_vector_store()
   │              └─ FAISS.similarity_search()
   │
   ├─ order_node()
   │    ├─ getdb(query)        ← 直接调用
   │    ├─ exec_sql(sql, params) ← 直接调用
   │    └─ _format_order_nlg(result) ← 直接调用
   │
   └─ handoff_node()
        ├─ record_unanswered(query) ← 直接调用
        └─ handoff_to_human(payload) ← 直接调用
   ↓
返回结果给用户
```

### 特点

**优点：**
- ✅ 简单直接，易于理解
- ✅ 无额外依赖
- ✅ 调用开销小
- ✅ 调试方便

**缺点：**
- ❌ 紧耦合，难以复用
- ❌ 无法被外部系统调用
- ❌ 无标准化接口
- ❌ 无工具发现机制

---

## Work V2/V3 的工具调用方式

### 架构图

```
┌──────────────────────────────────────────────────┐
│              外部系统                             │
│  (Claude Desktop / Cursor / 自定义客户端)        │
└────────────────┬─────────────────────────────────┘
                 │ MCP Protocol
                 │ (stdio/HTTP/SSE)
┌────────────────▼─────────────────────────────────┐
│         mcp_server.py (MCP 服务器)               │
│                                                   │
│  @mcp.tool()                                     │
│  def kb_search(query, k):                        │
│      return retrieve_kb(query)  ◄────────────────┼─┐
│                                                   │ │
│  @mcp.tool()                                     │ │
│  def order_lookup(text):                         │ │
│      payload = getdb(text)      ◄────────────────┼─┤
│      return exec_sql(...)       ◄────────────────┼─┤
│                                                   │ │
│  @mcp.tool()                                     │ │
│  def chat(query, thread_id):                     │ │
│      chain = build_graph()                       │ │
│      return chain.invoke(...)                    │ │
└───────────────────────────────────────────────────┘ │
                 ▲                                    │
                 │ 内部调用                           │
┌────────────────┴─────────────────────────────────┐ │
│         FastAPI 应用                              │ │
│                                                   │ │
│  app.mount("/mcp", mcp.sse_app())                │ │
│                                                   │ │
│  ┌────────────────────────────────────────────┐  │ │
│  │      LangGraph 状态机                       │  │ │
│  │                                             │  │ │
│  │  kb_node() → retrieve_kb()  ◄───────────────┼──┘
│  │  order_node() → getdb() + exec_sql() ◄──────┼────┘
│  │  handoff_node() → record_unanswered() ◄─────┼────┘
│  └─────────────────────────────────────────────┘  │
└───────────────────────────────────────────────────┘
                 │
┌────────────────▼─────────────────────────────────┐
│         tools.py (工具函数库)                     │
│  - retrieve_kb()                                 │
│  - getdb()                                       │
│  - exec_sql()                                    │
│  - record_unanswered()                           │
│  - handoff_to_human()                            │
└──────────────────────────────────────────────────┘
```

### 代码示例

#### 1. MCP 工具定义

```python
# work_v2/mcp_server.py

from mcp.server.fastmcp import FastMCP
from tools import retrieve_kb, getdb, exec_sql, load_course_catalog
from graph import build_graph

mcp = FastMCP("EduAgent MCP")

@mcp.tool()
def kb_search(query: str, k: int = 2) -> Dict[str, Any]:
    """知识库检索工具 - 通过 MCP 暴露"""
    serialized, docs = retrieve_kb(query)
    try:
        sources = [getattr(d, "metadata", {}) for d in (docs or [])]
    except Exception:
        sources = []
    return {"context": serialized, "sources": sources[:k]}

@mcp.tool()
def order_lookup(text: str) -> Dict[str, Any]:
    """订单查询工具 - 通过 MCP 暴露"""
    payload = getdb(text)
    sql = payload.get("sql")
    params = payload.get("params")
    result = None
    try:
        result = exec_sql(sql, params)
    except Exception:
        result = None
    if result is None:
        result = payload.get("mock") or {}
    return result

@mcp.tool()
def course_catalog(limit: int = 20) -> Dict[str, Any]:
    """课程目录工具 - 通过 MCP 暴露"""
    data = load_course_catalog()
    items = list(data.get("items", []))[:limit]
    return {"sections": list(data.get("sections", [])), "items": items}

@mcp.tool()
def chat(query: str, thread_id: Optional[str] = None) -> Dict[str, Any]:
    """完整对话工具 - 通过 MCP 暴露"""
    chain = build_graph()
    state = {"query": (query or "").strip(), "history": ""}
    cfg = {"configurable": {"thread_id": thread_id or "mcp"}}
    result = chain.invoke(state, cfg)
    route = result.get("route") or result.get("intent")
    # ... 处理结果
    return {"route": route, "answer": answer, "sources": sources}

@mcp.resource("kb://{query}")
def kb_resource(query: str) -> str:
    """知识库资源 - 通过 MCP 暴露"""
    serialized, _ = retrieve_kb(query)
    return serialized

@mcp.resource("orders://{order_id}")
def order_resource(order_id: str) -> Dict[str, Any]:
    """订单资源 - 通过 MCP 暴露"""
    p = getdb(order_id)
    res = exec_sql(p.get("sql"), p.get("params"))
    if res is None:
        res = p.get("mock") or {}
    return res
```

#### 2. FastAPI 集成

```python
# work_v2/app.py

from mcp_server import mcp as _mcp

# 创建 MCP SSE 应用
_mcp_app = _mcp.sse_app()

# 挂载到 FastAPI
app.mount("/mcp", _mcp_app)
```

#### 3. LangGraph 节点（保持不变）

```python
# work_v2/graph.py

# 节点内部仍然直接调用 tools.py
def kb_node(state: State) -> Dict[str, Any]:
    q = state.get("query", "")
    serialized, docs = retrieve_kb(q)  # 直接调用
    # ... 处理逻辑
    return {"kb_answer": content, "sources": sources}
```

### 调用流程

#### 内部调用（与 V1 相同）

```
用户请求
   ↓
FastAPI /chat 接口
   ↓
LangGraph.invoke(state)
   ↓
kb_node() → retrieve_kb(query)  ← 直接调用
   ↓
返回结果
```

#### 外部调用（新增）

```
外部系统 (Claude Desktop)
   ↓
MCP Protocol (stdio)
   ↓
mcp_server.py
   ↓
@mcp.tool() kb_search()
   ↓
retrieve_kb(query)  ← 调用相同的工具函数
   ↓
返回结果给外部系统
```

### 特点

**优点：**
- ✅ 双重接口：内部直接调用 + 外部 MCP 调用
- ✅ 标准化协议，易于集成
- ✅ 工具自动发现
- ✅ 支持多种传输方式
- ✅ 松耦合，易于扩展

**缺点：**
- ⚠️ 增加了一层抽象
- ⚠️ 需要额外依赖（mcp-server-fastmcp）
- ⚠️ 调试稍复杂

---

## 对比总结

### 调用方式对比

| 维度 | Work V1 | Work V2/V3 |
|------|---------|-----------|
| **内部调用** | 直接调用 tools.py | 直接调用 tools.py（相同） |
| **外部调用** | ❌ 不支持 | ✅ 通过 MCP 协议 |
| **工具暴露** | ❌ 无 | ✅ @mcp.tool() 装饰器 |
| **标准化** | ❌ 无 | ✅ MCP 协议 |
| **工具发现** | ❌ 无 | ✅ 自动发现 |
| **多传输** | ❌ 仅 HTTP | ✅ stdio/HTTP/SSE |
| **AI 集成** | ❌ 需要自定义 | ✅ 原生支持 |

### 代码复用

**V1：**
```python
# 仅在 graph.py 中使用
from tools import retrieve_kb
serialized, docs = retrieve_kb(query)
```

**V2/V3：**
```python
# 1. 在 graph.py 中使用（内部）
from tools import retrieve_kb
serialized, docs = retrieve_kb(query)

# 2. 在 mcp_server.py 中暴露（外部）
@mcp.tool()
def kb_search(query: str, k: int = 2):
    serialized, docs = retrieve_kb(query)
    return {"context": serialized, "sources": sources}

# 3. 外部系统调用
# Claude Desktop / Cursor / 自定义客户端
result = mcp_client.call_tool("kb_search", {"query": "Python课程"})
```

### 架构演进

```
V1: 单一调用路径
┌─────────┐
│ FastAPI │
└────┬────┘
     │ 直接调用
┌────▼────┐
│ tools.py│
└─────────┘

V2/V3: 双重调用路径
┌─────────┐     ┌──────────────┐
│ FastAPI │     │ 外部系统      │
└────┬────┘     └──────┬───────┘
     │ 直接调用         │ MCP 协议
     │           ┌─────▼─────┐
     │           │mcp_server │
     │           └─────┬─────┘
     │                 │ 调用
┌────▼─────────────────▼────┐
│       tools.py             │
└────────────────────────────┘
```

---

## 实际示例对比

### 场景：知识库检索

#### V1 实现

```python
# 只能在 FastAPI 内部使用
@app.post("/chat")
async def chat(req: ChatRequest):
    chain = build_graph()
    result = await chain.ainvoke(state, cfg)
    # chain 内部调用 retrieve_kb()
    return {"answer": result["kb_answer"]}
```

#### V2/V3 实现

```python
# 方式 1：FastAPI 内部使用（与 V1 相同）
@app.post("/chat")
async def chat(req: ChatRequest):
    chain = build_graph()
    result = await chain.ainvoke(state, cfg)
    return {"answer": result["kb_answer"]}

# 方式 2：MCP 工具调用（新增）
# 在 Claude Desktop 中：
用户: 帮我查询 Python 课程信息
Claude: [调用 kb_search 工具]
        根据知识库，Python 课程...

# 方式 3：HTTP API 调用（新增）
curl -X POST http://localhost:6278/tools/kb_search \
  -d '{"query":"Python课程","k":2}'
```

---

## 为什么要引入 MCP？

### V1 的痛点

1. **无法被外部系统调用**
   - Claude Desktop 想用知识库？不行
   - Cursor 想查订单？不行
   - 自定义脚本想批量处理？不行

2. **无标准化接口**
   - 每个外部系统需要自定义集成
   - 维护成本高

3. **功能无法复用**
   - 工具函数只能在内部使用
   - 无法作为服务提供

### V2/V3 的解决方案

1. **标准化协议**
   - MCP 是开放标准
   - 一次封装，多处使用

2. **AI 原生支持**
   - Claude Desktop 原生支持 MCP
   - Cursor 原生支持 MCP
   - 无需额外适配

3. **灵活的传输方式**
   - stdio：本地进程通信
   - HTTP：远程 API 调用
   - SSE：流式实时推送

---

## 总结

### V1 的工具调用

- **位置：** `graph.py` 的节点函数中
- **方式：** 直接 `from tools import xxx` 然后调用
- **特点：** 简单直接，仅供内部使用

### V2/V3 的工具调用

- **内部：** 与 V1 相同，直接调用 `tools.py`
- **外部：** 通过 `mcp_server.py` 暴露为 MCP 工具
- **特点：** 双重接口，内外兼顾

### 关键理解

**MCP 不是替代，而是增强：**
- 内部调用路径保持不变
- 新增外部调用路径
- 工具函数复用，无需重写

**类比：**
```
V1 = 私有函数库（只能自己用）
V2/V3 = 私有函数库 + 公共 API（自己用 + 别人用）
```

---

**文档版本：** v1.0  
**创建日期：** 2025-11-27  
**作者：** Kiro AI Assistant
